{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833c2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "import h5py\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold, SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31ea32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        filename = name.split('/')[0]\n",
    "        return pd.DataFrame(f[filename][:], dtype=np.float64)\n",
    "\n",
    "train = load_data('train')[1849:]\n",
    "test  = load_data('test')\n",
    "\n",
    "all_variables = ['p_Eratio', 'p_E5x7_Lr2', 'p_E3x5_Lr0','p_asy1', 'p_eClusterLr2', 'p_e235',\n",
    "                 'p_E_Lr3_HiG', 'p_e255']\n",
    "\n",
    "xtrain = train[all_variables].values\n",
    "xtest = test[all_variables].values\n",
    "\n",
    "scl = StandardScaler()\n",
    "xtrain_norm = scl.fit_transform(xtrain)\n",
    "xtest_norm = scl.fit_transform(xtest)\n",
    "xtrain_norm = pd.DataFrame(xtrain_norm)\n",
    "xtest_norm = pd.DataFrame(xtest_norm)\n",
    "xtrain_norm_cont = np.ascontiguousarray(xtrain_norm)\n",
    "xtest_norm_cont = np.ascontiguousarray(xtest_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d19747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN()\n",
    "result = model.fit(xtest_norm_cont)\n",
    "labels = result.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb76d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(labels)\n",
    "result.to_csv('Clustering_CooperNicolaysen_DBSCAN.csv', header = False, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d424698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
